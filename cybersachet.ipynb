{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37bba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Initialize OpenAI Client and Load Environment\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Initialize OpenAI client with API key\n",
    "openai_client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"âœ“ Environment loaded successfully\")\n",
    "print(f\"âœ“ OpenAI API key loaded: {api_key[:7]}...\")\n",
    "print(f\"âœ“ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc22f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Import additional libraries\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from pathlib import Path\n",
    "import json\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b47717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChromaDB initialized\n",
      "Collection 'cyber_sachet_docs' ready\n",
      "Current documents in collection: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initialize ChromaDB with OpenAI embeddings\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# Create OpenAI embedding function using the API key\n",
    "openai_ef = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=api_key,\n",
    "    model_name=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(\n",
    "    name=\"cyber_sachet_docs\",\n",
    "    embedding_function=openai_ef,\n",
    "    metadata={\"description\": \"Cyber awareness and Nepal cyber laws\"}\n",
    ")\n",
    "\n",
    "print(f\"ChromaDB initialized\")\n",
    "print(f\"Collection 'cyber_sachet_docs' ready\")\n",
    "print(f\"Current documents in collection: {collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1644c730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loading: cyber_awareness_guide.txt\n",
      "ðŸ“„ Loading: nepal_digital_security_act_2024.txt\n",
      "ðŸ“„ Loading: nepal_information_technology_act_2063.txt\n"
     ]
    },
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: <openai.********************************230>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} in add.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     39\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     40\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNo documents found to index\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mload_and_index_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mload_and_index_documents\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     28\u001b[39m             doc_id += \u001b[32m1\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m documents:\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[43mcollection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Indexed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(documents)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m chunks from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mlist\u001b[39m(docs_path.glob(\u001b[33m'\u001b[39m\u001b[33m*.txt\u001b[39m\u001b[33m'\u001b[39m)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m documents\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     38\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m Total documents in collection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection.count()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\Collection.py:97\u001b[39m, in \u001b[36mCollection.add\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd\u001b[39m(\n\u001b[32m     67\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     68\u001b[39m     ids: OneOrMany[ID],\n\u001b[32m   (...)\u001b[39m\u001b[32m     78\u001b[39m     uris: Optional[OneOrMany[URI]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     79\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     80\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Add records to the collection.\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m        ValueError: If an ID already exists.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     add_request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_prepare_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m        \u001b[49m\u001b[43muris\u001b[49m\u001b[43m=\u001b[49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m._client._add(\n\u001b[32m    107\u001b[39m         collection_id=\u001b[38;5;28mself\u001b[39m.id,\n\u001b[32m    108\u001b[39m         ids=add_request[\u001b[33m\"\u001b[39m\u001b[33mids\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m    114\u001b[39m         database=\u001b[38;5;28mself\u001b[39m.database,\n\u001b[32m    115\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:103\u001b[39m, in \u001b[36mvalidation_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m: Any, *args: Any, **kwargs: Any) -> T:\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    105\u001b[39m         msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:241\u001b[39m, in \u001b[36mCollectionCommon._validate_and_prepare_add_request\u001b[39m\u001b[34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    240\u001b[39m     validate_record_set_for_embedding(record_set=add_records)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     add_embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed_record_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43madd_records\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    243\u001b[39m     add_embeddings = add_records[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:724\u001b[39m, in \u001b[36mCollectionCommon._embed_record_set\u001b[39m\u001b[34m(self, record_set, embeddable_fields, is_query)\u001b[39m\n\u001b[32m    719\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embed(\n\u001b[32m    720\u001b[39m                 \u001b[38;5;28minput\u001b[39m=\u001b[38;5;28mself\u001b[39m._data_loader(uris=cast(URIs, record_set[field])),  \u001b[38;5;66;03m# type: ignore[literal-required]\u001b[39;00m\n\u001b[32m    721\u001b[39m                 is_query=is_query,\n\u001b[32m    722\u001b[39m             )\n\u001b[32m    723\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    725\u001b[39m \u001b[43m                \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mrecord_set\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[literal-required]\u001b[39;49;00m\n\u001b[32m    726\u001b[39m \u001b[43m                \u001b[49m\u001b[43mis_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    727\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    728\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    729\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRecord does not contain any non-None fields that can be embedded.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    730\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEmbeddable Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membeddable_fields\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    731\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRecord Fields: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecord_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    732\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\models\\CollectionCommon.py:741\u001b[39m, in \u001b[36mCollectionCommon._embed\u001b[39m\u001b[34m(self, input, is_query)\u001b[39m\n\u001b[32m    739\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function.embed_query(\u001b[38;5;28minput\u001b[39m=\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    740\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    743\u001b[39m config_ef = \u001b[38;5;28mself\u001b[39m.configuration.get(\u001b[33m\"\u001b[39m\u001b[33membedding_function\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config_ef \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\api\\types.py:859\u001b[39m, in \u001b[36mEmbeddingFunction.__init_subclass__.<locals>.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m: EmbeddingFunction[D], \u001b[38;5;28minput\u001b[39m: D) -> Embeddings:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m     result = \u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    860\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    861\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m validate_embeddings(cast(Embeddings, normalize_embeddings(result)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\chromadb\\utils\\embedding_functions\\openai_embedding_function.py:133\u001b[39m, in \u001b[36mOpenAIEmbeddingFunction.__call__\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m     embedding_params[\u001b[33m\"\u001b[39m\u001b[33mdimensions\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.dimensions\n\u001b[32m    132\u001b[39m \u001b[38;5;66;03m# Get embeddings\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43membedding_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Extract embeddings from response\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [np.array(data.embedding, dtype=np.float32) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m response.data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\openai\\resources\\embeddings.py:132\u001b[39m, in \u001b[36mEmbeddings.create\u001b[39m\u001b[34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m             embedding.embedding = np.frombuffer(  \u001b[38;5;66;03m# type: ignore[no-untyped-call]\u001b[39;00m\n\u001b[32m    127\u001b[39m                 base64.b64decode(data), dtype=\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    128\u001b[39m             ).tolist()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/embeddings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmbeddingCreateParams\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCreateEmbeddingResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1297\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1288\u001b[39m     warnings.warn(\n\u001b[32m   1289\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPassing raw bytes as `body` is deprecated and will be removed in a future version. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1290\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease pass raw bytes via the `content` parameter instead.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1291\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m   1292\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m   1293\u001b[39m     )\n\u001b[32m   1294\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1295\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, content=content, files=to_httpx_files(files), **options\n\u001b[32m   1296\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1297\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Cyber-Agent\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1070\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1067\u001b[39m             err.response.read()\n\u001b[32m   1069\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1070\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1072\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: <openai.********************************230>. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}} in add."
     ]
    }
   ],
   "source": [
    "\n",
    "def load_and_index_documents():\n",
    "    \"\"\"Load documents from docs folder and add them to vector database\"\"\"\n",
    "    docs_path = Path(\"docs\")\n",
    "    \n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "    \n",
    "    doc_id = 0\n",
    "    for doc_file in docs_path.glob(\"*.txt\"):\n",
    "        print(f\"ðŸ“„ Loading: {doc_file.name}\")\n",
    "        \n",
    "        with open(doc_file, 'r', encoding='utf-8') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "      \n",
    "        chunks = [chunk.strip() for chunk in content.split('\\n\\n') if chunk.strip()]\n",
    "        \n",
    "        for i, chunk in enumerate(chunks):\n",
    "            if len(chunk) > 50:  \n",
    "                documents.append(chunk)\n",
    "                metadatas.append({\n",
    "                    \"source\": doc_file.name,\n",
    "                    \"chunk_id\": i,\n",
    "                    \"doc_type\": \"cyber_law\" if \"act\" in doc_file.name.lower() else \"awareness\"\n",
    "                })\n",
    "                ids.append(f\"{doc_file.stem}_chunk_{i}\")\n",
    "                doc_id += 1\n",
    "    \n",
    "   \n",
    "    if documents:\n",
    "        collection.add(\n",
    "            documents=documents,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        print(f\"\\n Indexed {len(documents)} chunks from {len(list(docs_path.glob('*.txt')))} documents\")\n",
    "        print(f\" Total documents in collection: {collection.count()}\")\n",
    "    else:\n",
    "        print(\"No documents found to index\")\n",
    "\n",
    "\n",
    "load_and_index_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52aba6f",
   "metadata": {},
   "source": [
    "## Question 2: Search Tool Implementation\n",
    "\n",
    "### Tool Description:\n",
    "The **`semantic_search_tool`** performs vector-based semantic search on cyber security documents using ChromaDB and OpenAI embeddings.\n",
    "\n",
    "### What It Does:\n",
    "- Converts user queries into embeddings using OpenAI's text-embedding-3-small model\n",
    "- Searches through indexed cyber law documents and awareness guides\n",
    "- Returns the most relevant document chunks based on semantic similarity\n",
    "- Supports filtering by document type (laws vs awareness)\n",
    "- Provides relevance scores for each result\n",
    "\n",
    "### Function Signature:\n",
    "```python\n",
    "def semantic_search_tool(\n",
    "    query: str,\n",
    "    n_results: int = 5,\n",
    "    doc_type_filter: str = None\n",
    ") -> List[Dict[str, Any]]\n",
    "```\n",
    "\n",
    "**Inputs:**\n",
    "- `query` (str): The search query from the user\n",
    "- `n_results` (int, default=5): Number of results to return\n",
    "- `doc_type_filter` (str, optional): Filter by \"cyber_law\" or \"awareness\"\n",
    "\n",
    "**Outputs:**\n",
    "- List[Dict] containing:\n",
    "  - `content`: The text chunk from the document\n",
    "  - `source`: Original document filename\n",
    "  - `doc_type`: Type of document (cyber_law or awareness)\n",
    "  - `relevance_score`: Similarity score (0-1, higher is more relevant)\n",
    "  - `chunk_id`: Position in the original document\n",
    "\n",
    "### Challenges Faced:\n",
    "1. **Chunk Size Optimization**: Balancing between too small (loss of context) and too large (reduced precision)\n",
    "2. **Encoding Issues**: Handling UTF-8 characters in Nepal-specific documents\n",
    "3. **Metadata Management**: Tracking document source and maintaining relationships between chunks\n",
    "4. **Relevance Scoring**: Converting ChromaDB distance metrics to intuitive relevance scores\n",
    "5. **API Rate Limits**: Managing OpenAI API calls for embedding generation during indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5067d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "class CyberSearchTool:\n",
    "    \"\"\"\n",
    "    Semantic Search Tool for Cyber Sachet Agent\n",
    "    \n",
    "    This tool enables vector-based semantic search across cyber security\n",
    "    documents and Nepal's cyber law documentation.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, collection, embedding_function):\n",
    "        self.collection = collection\n",
    "        self.embedding_function = embedding_function\n",
    "    \n",
    "    def semantic_search_tool(\n",
    "        self, \n",
    "        query: str, \n",
    "        n_results: int = 5,\n",
    "        doc_type_filter: Optional[str] = None\n",
    "    ) -> List[Dict[str, Any]]:\n",
    "        \"\"\"\n",
    "        Perform semantic search on cyber security documents.\n",
    "        \n",
    "        Args:\n",
    "            query (str): The search query\n",
    "            n_results (int): Number of results to return (default: 5)\n",
    "            doc_type_filter (str, optional): Filter by \"cyber_law\" or \"awareness\"\n",
    "        \n",
    "        Returns:\n",
    "            List[Dict]: List of relevant document chunks with metadata\n",
    "                - content: The document text\n",
    "                - source: Original filename\n",
    "                - doc_type: Type of document\n",
    "                - relevance_score: Similarity score (0-1)\n",
    "                - chunk_id: Position in document\n",
    "        \"\"\"\n",
    "        \n",
    "        # Build query parameters\n",
    "        query_params = {\n",
    "            \"query_texts\": [query],\n",
    "            \"n_results\": n_results\n",
    "        }\n",
    "        \n",
    "        # Add filter if specified\n",
    "        if doc_type_filter:\n",
    "            query_params[\"where\"] = {\"doc_type\": doc_type_filter}\n",
    "        \n",
    "        # Perform vector search\n",
    "        results = self.collection.query(**query_params)\n",
    "        \n",
    "        # Format results\n",
    "        search_results = []\n",
    "        if results['documents'][0]:\n",
    "            for i in range(len(results['documents'][0])):\n",
    "                # Calculate relevance score (1 - normalized distance)\n",
    "                distance = results['distances'][0][i] if 'distances' in results else 0\n",
    "                relevance_score = max(0, 1 - distance)\n",
    "                \n",
    "                search_results.append({\n",
    "                    'content': results['documents'][0][i],\n",
    "                    'source': results['metadatas'][0][i]['source'],\n",
    "                    'doc_type': results['metadatas'][0][i]['doc_type'],\n",
    "                    'relevance_score': round(relevance_score, 3),\n",
    "                    'chunk_id': results['metadatas'][0][i]['chunk_id']\n",
    "                })\n",
    "        \n",
    "        return search_results\n",
    "    \n",
    "    def search_laws_only(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search only in cyber law documents\"\"\"\n",
    "        return self.semantic_search_tool(query, n_results, \"cyber_law\")\n",
    "    \n",
    "    def search_awareness_only(self, query: str, n_results: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search only in awareness documents\"\"\"\n",
    "        return self.semantic_search_tool(query, n_results, \"awareness\")\n",
    "    \n",
    "    def get_all_sources(self) -> List[str]:\n",
    "        \"\"\"Get list of all indexed document sources\"\"\"\n",
    "        all_data = self.collection.get()\n",
    "        sources = set([meta['source'] for meta in all_data['metadatas']])\n",
    "        return sorted(list(sources))\n",
    "\n",
    "# Initialize the search tool\n",
    "search_tool = CyberSearchTool(collection, openai_ef)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ” SEARCH TOOL IMPLEMENTATION COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nðŸ“š Indexed Documents:\")\n",
    "for i, source in enumerate(search_tool.get_all_sources(), 1):\n",
    "    print(f\"   {i}. {source}\")\n",
    "\n",
    "print(\"\\nðŸ› ï¸  Available Search Functions:\")\n",
    "print(\"   â€¢ semantic_search_tool() - General semantic search\")\n",
    "print(\"   â€¢ search_laws_only() - Search cyber law documents\")\n",
    "print(\"   â€¢ search_awareness_only() - Search awareness guides\")\n",
    "print(\"   â€¢ get_all_sources() - List all indexed documents\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Testing the Search Tool...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Test the search tool\n",
    "test_query = \"What are the penalties for cyber crimes in Nepal?\"\n",
    "print(f\"\\nðŸ”Ž Query: '{test_query}'\")\n",
    "print(f\"ðŸ“Š Searching...\")\n",
    "\n",
    "results = search_tool.semantic_search_tool(test_query, n_results=3)\n",
    "\n",
    "print(f\"\\nâœ… Found {len(results)} relevant results:\\n\")\n",
    "\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"Result {i}:\")\n",
    "    print(f\"  ðŸ“„ Source: {result['source']}\")\n",
    "    print(f\"  ðŸ·ï¸  Type: {result['doc_type']}\")\n",
    "    print(f\"  â­ Relevance: {result['relevance_score']}\")\n",
    "    print(f\"  ðŸ“ Content Preview: {result['content'][:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a55931",
   "metadata": {},
   "source": [
    "## Question 3: Agent Creation with Tools\n",
    "\n",
    "### Agent Instructions/Prompt:\n",
    "\n",
    "The Cyber Sachet Agent is created with the following system prompt and capabilities:\n",
    "\n",
    "**System Prompt:**\n",
    "```\n",
    "You are Cyber Sachet, an AI assistant specializing in cyber security awareness \n",
    "and Nepal's cyber laws (IT Act 2063, Digital Security Act 2024).\n",
    "\n",
    "Your mission:\n",
    "1. Provide accurate, helpful information about cyber security\n",
    "2. Explain Nepal's cyber laws in clear, accessible language\n",
    "3. Offer practical security advice and best practices\n",
    "4. Use the semantic_search_tool to find relevant information\n",
    "5. Always cite sources when referencing specific laws\n",
    "6. Be educational, empathetic, and solution-oriented\n",
    "\n",
    "When answering:\n",
    "- First use the search tool to gather relevant context\n",
    "- Synthesize information from multiple sources\n",
    "- Provide actionable advice\n",
    "- Cite the document source for legal information\n",
    "- If uncertain, clearly state limitations\n",
    "```\n",
    "\n",
    "**Available Tools:**\n",
    "1. `semantic_search_tool()` - Semantic search across all documents\n",
    "2. `search_laws_only()` - Search only cyber law documents\n",
    "3. `search_awareness_only()` - Search only awareness guides\n",
    "\n",
    "**Agent Architecture:**\n",
    "- Uses RAG (Retrieval Augmented Generation) approach\n",
    "- OpenAI GPT-4o-mini for responses\n",
    "- ChromaDB for vector storage and retrieval\n",
    "- Context window: Up to 5 relevant document chunks per query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada8d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: QUESTION 3 - Create the Agent with Search Tools\n",
    "\n",
    "class CyberSachetAgent:\n",
    "    \"\"\"\n",
    "    Cyber Sachet Agent - AI Assistant for Cyber Security and Nepal Cyber Laws\n",
    "    \n",
    "    Uses RAG (Retrieval Augmented Generation) with semantic search tools\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, search_tool: CyberSearchTool, openai_client):\n",
    "        self.search_tool = search_tool\n",
    "        self.client = openai_client\n",
    "        \n",
    "        # Agent's system prompt\n",
    "        self.system_prompt = \"\"\"You are Cyber Sachet, an AI assistant specializing in cyber security awareness \n",
    "and Nepal's cyber laws (IT Act 2063, Digital Security Act 2024).\n",
    "\n",
    "Your mission:\n",
    "1. Provide accurate, helpful information about cyber security\n",
    "2. Explain Nepal's cyber laws in clear, accessible language\n",
    "3. Offer practical security advice and best practices\n",
    "4. Always cite sources when referencing specific laws or regulations\n",
    "5. Be educational, empathetic, and solution-oriented\n",
    "\n",
    "When answering questions:\n",
    "- Synthesize information from the provided context documents\n",
    "- Provide actionable, practical advice\n",
    "- Cite the specific document source for legal information (e.g., \"According to Nepal IT Act 2063...\")\n",
    "- Use clear, simple language that non-technical users can understand\n",
    "- If the context doesn't contain the answer, use your general knowledge but clearly state that\n",
    "- For cyber security tips, prioritize practical, implementable advice\n",
    "\n",
    "Remember: Your goal is to educate and empower users about cyber security and their legal rights/responsibilities.\"\"\"\n",
    "    \n",
    "    def query(self, user_question: str, n_context_docs: int = 5, verbose: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Query the agent with a question.\n",
    "        \n",
    "        Args:\n",
    "            user_question (str): User's question\n",
    "            n_context_docs (int): Number of context documents to retrieve\n",
    "            verbose (bool): Print search process details\n",
    "        \n",
    "        Returns:\n",
    "            Dict containing the answer, sources used, and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ðŸ” Searching knowledge base for: '{user_question}'\")\n",
    "        \n",
    "        # Use the search tool to retrieve relevant context\n",
    "        search_results = self.search_tool.semantic_search_tool(\n",
    "            query=user_question,\n",
    "            n_results=n_context_docs\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ðŸ“š Retrieved {len(search_results)} relevant documents\")\n",
    "            for i, r in enumerate(search_results[:3], 1):\n",
    "                print(f\"   {i}. {r['source']} (relevance: {r['relevance_score']})\")\n",
    "        \n",
    "        # Build context from search results\n",
    "        context_parts = []\n",
    "        sources_used = set()\n",
    "        \n",
    "        for result in search_results:\n",
    "            context_parts.append(\n",
    "                f\"[Source: {result['source']}, Type: {result['doc_type']}, Relevance: {result['relevance_score']}]\\n\"\n",
    "                f\"{result['content']}\"\n",
    "            )\n",
    "            sources_used.add(result['source'])\n",
    "        \n",
    "        context = \"\\n\\n---\\n\\n\".join(context_parts)\n",
    "        \n",
    "        # Build the user message with context\n",
    "        user_message = f\"\"\"Based on the following context from cyber security documents and Nepal's cyber laws, \n",
    "please answer the user's question comprehensively.\n",
    "\n",
    "CONTEXT DOCUMENTS:\n",
    "{context}\n",
    "\n",
    "USER QUESTION: {user_question}\n",
    "\n",
    "Please provide a comprehensive, well-structured answer. If referencing specific laws or regulations, \n",
    "cite the source document. Make your answer practical and actionable.\"\"\"\n",
    "        \n",
    "        # Call OpenAI API\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": self.system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"ðŸ¤– Generating response...\\n\")\n",
    "        \n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0.7,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        return {\n",
    "            \"question\": user_question,\n",
    "            \"answer\": answer,\n",
    "            \"sources_used\": list(sources_used),\n",
    "            \"num_context_docs\": len(search_results),\n",
    "            \"search_results\": search_results\n",
    "        }\n",
    "    \n",
    "    def quick_query(self, user_question: str) -> str:\n",
    "        \"\"\"Quick query that just returns the answer\"\"\"\n",
    "        result = self.query(user_question, verbose=False)\n",
    "        return result[\"answer\"]\n",
    "\n",
    "# Initialize the agent\n",
    "agent = CyberSachetAgent(search_tool, openai_client)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ðŸ¤– CYBER SACHET AGENT INITIALIZED\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nâœ… Agent is ready with:\")\n",
    "print(\"   â€¢ Semantic search capabilities\")\n",
    "print(\"   â€¢ Access to Nepal cyber law documents\")\n",
    "print(\"   â€¢ Cyber security awareness knowledge\")\n",
    "print(\"   â€¢ RAG-based response generation\")\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11632ffc",
   "metadata": {},
   "source": [
    "## Example Interactions\n",
    "\n",
    "Below are example interactions showing how the agent uses the search tool to answer questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Example Interaction 1 - Legal Question\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"EXAMPLE INTERACTION 1: Legal Question\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "question1 = \"What are the penalties for hacking and unauthorized access in Nepal?\"\n",
    "\n",
    "print(f\"ðŸ‘¤ User: {question1}\\n\")\n",
    "\n",
    "result1 = agent.query(question1, n_context_docs=5)\n",
    "\n",
    "print(f\"ðŸ’¬ Cyber Sachet Agent:\\n{result1['answer']}\\n\")\n",
    "\n",
    "print(\"â”\" * 70)\n",
    "print(f\"ðŸ“Š Metadata:\")\n",
    "print(f\"   Sources Used: {', '.join(result1['sources_used'])}\")\n",
    "print(f\"   Context Documents Retrieved: {result1['num_context_docs']}\")\n",
    "print(f\"   Top Relevance Score: {result1['search_results'][0]['relevance_score']}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848ab56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Example Interaction 2 - Security Awareness Question\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE INTERACTION 2: Security Awareness Question\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "question2 = \"How can I protect myself from phishing attacks?\"\n",
    "\n",
    "print(f\"ðŸ‘¤ User: {question2}\\n\")\n",
    "\n",
    "result2 = agent.query(question2, n_context_docs=4)\n",
    "\n",
    "print(f\"ðŸ’¬ Cyber Sachet Agent:\\n{result2['answer']}\\n\")\n",
    "\n",
    "print(\"â”\" * 70)\n",
    "print(f\"ðŸ“Š Metadata:\")\n",
    "print(f\"   Sources Used: {', '.join(result2['sources_used'])}\")\n",
    "print(f\"   Context Documents Retrieved: {result2['num_context_docs']}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0d78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Example Interaction 3 - Mixed Question (Law + Awareness)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"EXAMPLE INTERACTION 3: Mixed Question (Law + Awareness)\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "\n",
    "question3 = \"What should I do if I become a victim of cybercrime in Nepal?\"\n",
    "\n",
    "print(f\"ðŸ‘¤ User: {question3}\\n\")\n",
    "\n",
    "result3 = agent.query(question3, n_context_docs=5)\n",
    "\n",
    "print(f\"ðŸ’¬ Cyber Sachet Agent:\\n{result3['answer']}\\n\")\n",
    "\n",
    "print(\"â”\" * 70)\n",
    "print(f\"ðŸ“Š Metadata:\")\n",
    "print(f\"   Sources Used: {', '.join(result3['sources_used'])}\")\n",
    "print(f\"   Context Documents Retrieved: {result3['num_context_docs']}\")\n",
    "print(f\"   Document Types: {set([r['doc_type'] for r in result3['search_results']])}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ca6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Demonstrate Tool Usage - Search-Only Examples\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DEMONSTRATING SEARCH TOOL USAGE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Example 1: General search\n",
    "print(\"\\n1ï¸âƒ£ General Semantic Search:\")\n",
    "print(\"Query: 'data privacy'\")\n",
    "privacy_results = search_tool.semantic_search_tool(\"data privacy\", n_results=3)\n",
    "for i, r in enumerate(privacy_results, 1):\n",
    "    print(f\"\\n   Result {i}:\")\n",
    "    print(f\"   Source: {r['source']}\")\n",
    "    print(f\"   Relevance: {r['relevance_score']}\")\n",
    "    print(f\"   Preview: {r['content'][:100]}...\")\n",
    "\n",
    "# Example 2: Laws only\n",
    "print(\"\\n\\n2ï¸âƒ£ Search Laws Only:\")\n",
    "print(\"Query: 'punishment'\")\n",
    "law_results = search_tool.search_laws_only(\"punishment\", n_results=2)\n",
    "for i, r in enumerate(law_results, 1):\n",
    "    print(f\"\\n   Result {i}:\")\n",
    "    print(f\"   Source: {r['source']}\")\n",
    "    print(f\"   Relevance: {r['relevance_score']}\")\n",
    "    print(f\"   Preview: {r['content'][:100]}...\")\n",
    "\n",
    "# Example 3: Awareness only\n",
    "print(\"\\n\\n3ï¸âƒ£ Search Awareness Guides Only:\")\n",
    "print(\"Query: 'password security'\")\n",
    "awareness_results = search_tool.search_awareness_only(\"password security\", n_results=2)\n",
    "for i, r in enumerate(awareness_results, 1):\n",
    "    print(f\"\\n   Result {i}:\")\n",
    "    print(f\"   Source: {r['source']}\")\n",
    "    print(f\"   Relevance: {r['relevance_score']}\")\n",
    "    print(f\"   Preview: {r['content'][:100]}...\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"âœ… ALL DEMONSTRATIONS COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314d6fe9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Question 2: Search Tool Implementation âœ…\n",
    "\n",
    "**Tool Name:** `semantic_search_tool`\n",
    "\n",
    "**Function Signature:**\n",
    "```python\n",
    "def semantic_search_tool(\n",
    "    query: str, \n",
    "    n_results: int = 5,\n",
    "    doc_type_filter: Optional[str] = None\n",
    ") -> List[Dict[str, Any]]\n",
    "```\n",
    "\n",
    "**Inputs:**\n",
    "- `query`: User's search query\n",
    "- `n_results`: Number of results (default: 5)\n",
    "- `doc_type_filter`: Optional filter for document type\n",
    "\n",
    "**Outputs:**\n",
    "- List of dictionaries with: content, source, doc_type, relevance_score, chunk_id\n",
    "\n",
    "**Challenges:**\n",
    "1. Chunk size optimization\n",
    "2. UTF-8 encoding for Nepali documents\n",
    "3. Metadata management across chunks\n",
    "4. Distance to relevance score conversion\n",
    "5. API rate limiting during indexing\n",
    "\n",
    "---\n",
    "\n",
    "### Question 3: Agent with Tools âœ…\n",
    "\n",
    "**Agent Name:** Cyber Sachet Agent\n",
    "\n",
    "**System Prompt:** Educational AI assistant for cyber security and Nepal cyber laws with RAG capabilities\n",
    "\n",
    "**Tools Integrated:**\n",
    "- `semantic_search_tool()` - General search\n",
    "- `search_laws_only()` - Law-specific search\n",
    "- `search_awareness_only()` - Awareness-specific search\n",
    "\n",
    "**Example Interactions:** Demonstrated with 3 different query types showing tool usage, sources, and relevance scores\n",
    "\n",
    "**Architecture:** RAG approach using ChromaDB + OpenAI embeddings + GPT-4o-mini"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber-agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
